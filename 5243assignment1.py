# -*- coding: utf-8 -*-
"""5243assignment1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ERGw1Cmx5x9T69mgkDalWDIXK4bJR-iZ
"""

import pandas as pd
import numpy as np
import nltk
import matplotlib.pyplot as plt
from nltk.stem import PorterStemmer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score, roc_curve, auc
import time

nltk.download('punkt')
nltk.download('punkt_tab')

# Load and validation
df = pd.read_csv('merged_dataset.txt', sep='\t', names=['sentence', 'label'], header=None)
print(f"Dataset Shape: {df.shape}")
print(df.head())

# Word stemming and vector creation
stemmer = PorterStemmer()

def preprocess_text(text):
    tokens = nltk.word_tokenize(text.lower())
    stemmed = [stemmer.stem(word) for word in tokens if word.isalnum()]
    return " ".join(stemmed)

df['cleaned_sentence'] = df['sentence'].apply(preprocess_text)

vectorizer = CountVectorizer()
x = vectorizer.fit_transform(df['cleaned_sentence'])
y = df['label']

# Dataset split

# 60/40 train/temp split, where temp split will be split again
x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.4, random_state=42)
x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)

print(f"Train size: {x_train.shape[0]}, Val size: {x_val.shape[0]}, Test size: {x_test.shape[0]}")
print(x.shape[0])
print(x_train.shape[0] + x_val.shape[0] + x_test.shape[0])

# Top-k feature selection with exclusion of common words

stop_words_list = ['a', 'the', 'an', 'and', 'or', 'but', 'is', 'are', 'was', 'were']
vectorizer_top_k = CountVectorizer(stop_words=stop_words_list, max_features=1024)
x_top_k = vectorizer_top_k.fit_transform(df['cleaned_sentence'])

print(f"Top-K Feature Matrix Shape: {x_top_k.shape}")

# Split the top-k features using the same random state to ensure alignment
x_train_k, x_temp_k, y_train_k, y_temp_k = train_test_split(x_top_k, y, test_size=0.4, random_state=42)
x_val_k, x_test_k, y_val_k, y_test_k = train_test_split(x_temp_k, y_temp_k, test_size=0.5, random_state=42)

# Establish own KNN Algorithm
class CustomKNN:
  def __init__(self, k=5):
    self.k = k

  # Passing in the training data
  def fit(self, x, y):
    self.x_train = x.toarray() if hasattr(x, "toarray") else x
    self.y_train = np.array(y)

  # Fitting of each point
  def predict(self, x):
    x_input = x.toarray() if hasattr(x, "toarray") else x
    predictions = []
    for row in x_input:
      # Euclidean distance calculation
      distances = np.linalg.norm(self.x_train - row, axis=1)
      k_indices = np.argsort(distances)[:self.k]
      k_nearest_labels = self.y_train[k_indices]
      # Majority vote
      counts = np.bincount(k_nearest_labels)
      predictions.append(np.argmax(counts))
    return np.array(predictions)

# Initialize the three classifiers that will be used
models = {
    "CL-1 (KNN)": CustomKNN(k=5),
    "CL-2 (Naive Bayes)": MultinomialNB(),
    "CL-3 (Decision Tree)": DecisionTreeClassifier()
}

def run_evaluation(model, x_train, y_train, x_eval, y_eval):
  # Model build efficiency
  start_train = time.time()
  model.fit(x_train, y_train)
  offline_cost = time.time() - start_train

  # Model predict efficiency
  start_pred = time.time()
  y_pred = model.predict(x_eval)
  online_cost = time.time() - start_pred

  # Accuracy, Precision, Recall, Specificity
  acc = accuracy_score(y_eval, y_pred)
  prec = precision_score(y_eval, y_pred)
  rec = recall_score(y_eval, y_pred)
  tn, fp, fn, tp = confusion_matrix(y_eval, y_pred).ravel()
  spec = tn / (tn + fp)

  # AUROC
  try:
    if hasattr(model, "predict_proba"):
      y_prob = model.predict_proba(x_eval)[:, 1]
    else:
      y_prob = y_pred

    # Calculate AUROC here for both cases
    auroc = roc_auc_score(y_eval, y_prob)
  except:
    auroc = np.nan

  return {
      "Accuracy": acc, "Precision": prec, "Recall": rec,
      "Specificity": spec, "AUROC": auroc,
      "Offline Cost": offline_cost, "Online Cost": online_cost
      }

# Define
feature_sets = {
    "FV-1": (x_train, x_test, y_train, y_test),
    "FV-2 (Top-1024)": (x_train_k, x_test_k, y_train_k, y_test_k)
}

# Run 6 experiments
all_results = {}
for fv_name, (xtr, xte, ytr, yte) in feature_sets.items():
    for model_name, model in models.items():
        # Create a descriptive key
        key = f"{model_name} [{fv_name}]"
        all_results[key] = run_evaluation(model, xtr, ytr, xte, yte)

# Load data to dataframe
results_df = pd.DataFrame(all_results).T
print(results_df)

def plot_roc_curves(models, x_test, y_test, feature_set_name):
    plt.figure(figsize=(10, 7))

    for name, model in models.items():
        # Get prediction probabilities or scores
        if hasattr(model, "predict_proba"):
            y_score = model.predict_proba(x_test)[:, 1]
        else:
            y_score = model.predict(x_test)

        fpr, tpr, _ = roc_curve(y_test, y_score)
        roc_auc = auc(fpr, tpr)

        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:0.2f})')

    # Plot the random chance line
    plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')

    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate (1 - Specificity)')
    plt.ylabel('True Positive Rate (Sensitivity)')
    plt.title(f'ROC Curves - {feature_set_name}')
    plt.legend(loc="lower right")
    plt.grid(alpha=0.3)
    plt.show()

# Retrain models on FV-1 data before plotting because they were last trained on FV-2
for name, model in models.items():
    model.fit(x_train, y_train)

plot_roc_curves(models, x_test, y_test, "Original Features (FV-1)")

# Retain and plot for FV-2
for name, model in models.items():
     model.fit(x_train_k, y_train_k)
plot_roc_curves(models, x_test_k, y_test_k, "Pruned Features (FV-2)")